{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbc57931",
   "metadata": {},
   "source": [
    "# exaSPIM example workflow\n",
    "\n",
    "## Intro\n",
    "\n",
    "This notebook provides a proof of principle for processing a exaSPIM dataset comprised of:\n",
    "- 15 tiles (5x3 grid)\n",
    "- 2 channels\n",
    "- Full data size ~ 150 TB\n",
    "\n",
    "The data is made available by the Allen Institute for Neural Dynamics and browseable via https://open.quiltdata.com/b/aind-open-data/tree/?prefix=exa.\n",
    "\n",
    "## Setup\n",
    "\n",
    "1. Setup Python in your preferred way (e.g. conda, venv, pipenv, poetry, etc.)\n",
    "1. Make sure `multiview-stitcher >= 0.1.35` is installed: `pip install \"multiview-stitcher>=0.1.35\"`\n",
    "1. Optionally, install `ray` for parallelising fusion on top of dask: `pip install \"ray[default]\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f73165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import dask.array as da\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "import ngff_zarr\n",
    "import pydantic_bigstitcher as pbs\n",
    "\n",
    "from multiview_stitcher import spatial_image_utils as si_utils\n",
    "from multiview_stitcher import (\n",
    "    registration,\n",
    "    fusion,\n",
    "    param_utils,\n",
    "    msi_utils,\n",
    "    misc_utils,\n",
    "    vis_utils,\n",
    "    ngff_utils,\n",
    ")\n",
    "\n",
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9884853",
   "metadata": {},
   "source": [
    "## Define input paths\n",
    "\n",
    "All data lives in the cloud in OME-Zarr format and we can directly access it via the web urls. Here we set the URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a10a049",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_url = \"https://aind-open-data.s3.amazonaws.com\"\n",
    "\n",
    "base_path = \"exaSPIM_674185_2023-10-02_14-06-36\"\n",
    "first_tile_path = \"exaSPIM.zarr/tile_x_0000_y_0000_z_0000_ch_488.zarr\"\n",
    "metadata_path = \"exaSPIM_acquisition.json\"\n",
    "\n",
    "n_tiles_x = 5\n",
    "n_tiles_y = 3\n",
    "# n_tiles_x = 2\n",
    "# n_tiles_y = 1\n",
    "channels = [\"561\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34e81e5",
   "metadata": {},
   "source": [
    "## Read data and metadata\n",
    "\n",
    "Note that no pixel data is read at this stage, only metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fceda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load OME-Zarr multiscale images\n",
    "\n",
    "df = []\n",
    "for ix in range(n_tiles_x):\n",
    "    for iy in range(n_tiles_y):\n",
    "        for ch in channels:\n",
    "            # TODO: this could be cleaner\n",
    "            tile_path = first_tile_path.replace(\"tile_x_0000_y_0000\", f\"tile_x_{ix:04d}_y_{iy:04d}\")\n",
    "            tile_path = tile_path.replace(\"ch_488\", f\"ch_{ch}\")\n",
    "            file_url = os.path.join(bucket_url, base_path, tile_path)\n",
    "            print(f\"Loading tile x={ix}, y={iy}, ch={ch}... filepath={tile_path}\")\n",
    "            msim = ngff_utils.ngff_multiscales_to_msim(\n",
    "                ngff_zarr.from_ngff_zarr(file_url),\n",
    "                transform_key='ome-zarr'\n",
    "                )\n",
    "            df.append({\n",
    "                'ix': ix,\n",
    "                'iy': iy,\n",
    "                'filename': os.path.basename(tile_path),\n",
    "                'file_url': file_url,\n",
    "                'ch': ch,\n",
    "                'msim': msim\n",
    "                })\n",
    "\n",
    "# combine everything into a dataframe\n",
    "df = pd.DataFrame(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f202ba7c",
   "metadata": {},
   "source": [
    "## Correct origins for multiscale data\n",
    "\n",
    "The OME-Zarr files contain multiscale data. However, the origins of the different scales are not correctly set. We correct them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e13352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_origins(msim):\n",
    "    # # correct origins at each scale\n",
    "    sks = msi_utils.get_sorted_scale_keys(msim)\n",
    "    spacing0 = si_utils.get_spacing_from_sim(msi_utils.get_sim_from_msim(msim, sks[0]))\n",
    "    origin0 = si_utils.get_origin_from_sim(msi_utils.get_sim_from_msim(msim, sks[0]))\n",
    "    sdims = msi_utils.get_spatial_dims(msim)\n",
    "\n",
    "    sim0 = msi_utils.get_sim_from_msim(msim, sks[0])\n",
    "    shape0 = {dim: len(sim0.coords[dim]) for dim in sdims}\n",
    "    msim = msim.map_over_datasets(lambda ds: xr.Dataset(\n",
    "        {'image': ds.image.assign_coords(\n",
    "            {dim: ds.image.coords[dim] - ds.image.coords[dim].values[0] + origin0[dim]\\\n",
    "              + (np.round(shape0[dim] / len(ds.image.coords[dim])) - 1) / 2 * spacing0[dim]\n",
    "              for dim in sdims}\n",
    "                )} | \\\n",
    "        {t: ds.data_vars[t] for t in ds.data_vars if t != 'image'})\n",
    "        if len(ds.data_vars) > 0 else ds)\n",
    "\n",
    "    return msim\n",
    "\n",
    "df['msim'] = df['msim'].apply(lambda msim: correct_origins(msim))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff75b6e",
   "metadata": {},
   "source": [
    "## Visualize tile configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12168d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the tile configuration and check it's properly set\n",
    "from multiview_stitcher import vis_utils, msi_utils, fusion\n",
    "vis_utils.plot_positions(\n",
    "    df[\"msim\"].tolist(), transform_key='ome-zarr'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf698be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(vis_utils)\n",
    "\n",
    "vis_utils.view_neuroglancer(\n",
    "    df['file_url'].tolist(),\n",
    "    sims=[msi_utils.get_sim_from_msim(msim) for msim in df['msim']],\n",
    "    transform_key='ome-zarr',\n",
    "    contrast_limits=(0, 150),\n",
    "    single_layer=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8f556b",
   "metadata": {},
   "source": [
    "## Registration\n",
    "\n",
    "Here, we'll use phase correlation based registration to register the tiles.\n",
    "\n",
    "Note that this step (currently) requires that at least the overlap of two neighboring tiles needs to fit into memory.\n",
    "\n",
    "How to achieve this?\n",
    "- choose a suitable scale to register on\n",
    "- advanced: Define a [custom registration function](https://multiview-stitcher.github.io/multiview-stitcher/main/extension_api_pairwise_registration/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6554d941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print data sizes for the different scales\n",
    "print(\"Data sizes for different scales (first tile):\")\n",
    "msim = df['msim'][0]\n",
    "print('Dimensions:', msim['scale0/image'].dims)\n",
    "for scale in msim:\n",
    "    print(f\"Scale {scale}: {msim[scale].image.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980cc2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiview_stitcher import registration\n",
    "import dask.diagnostics\n",
    "\n",
    "with dask.diagnostics.ProgressBar():\n",
    "    registration.register(\n",
    "            df['msim'].tolist(),\n",
    "            transform_key='ome-zarr',\n",
    "            new_transform_key='phase_corr',\n",
    "            reg_channel_index=0,\n",
    "            # registration_binning={'z': 1, 'y': 1, 'x': 1},\n",
    "            reg_res_level=5,\n",
    "            n_parallel_pairwise_regs=2,  # trade-off speed vs memory requirements (estimate of required memory: 2 * n_parallel_pairwise_regs * overlap_data_size))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b015785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize obtained tile configuration after registration\n",
    "# (this doesn't show image data so we can mostly use it to\n",
    "# get an idea of the corrected tile layout)\n",
    "\n",
    "vis_utils.plot_positions(\n",
    "    df[\"msim\"].tolist(), transform_key='phase_corr'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7cee55",
   "metadata": {},
   "source": [
    "## Visualize segmentation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d636bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_utils.view_neuroglancer(\n",
    "    df['file_url'].tolist(),\n",
    "    sims=[msi_utils.get_sim_from_msim(msim) for msim in df['msim']],\n",
    "    transform_key='phase_corr',\n",
    "    single_layer=True, # setting this to true can improve neuroglancer performance\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37df4d61",
   "metadata": {},
   "source": [
    "## Fusion\n",
    "\n",
    "We save the output to a (local) multiscale OME-Zarr file.\n",
    "\n",
    "The progress bar gives an estimate of the processing time. Different scales can be used for fusion. Also different shapes and offsets can be specified for the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d7d5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output Zarr URL\n",
    "# make sure to set an unexisting / unused output path\n",
    "output_zarr_url = \"fused_exa.zarr\"\n",
    "\n",
    "# define which transform key to use for fusion\n",
    "# fusion_transform_key = 'ome-zarr' # fuse without alignment\n",
    "fusion_transform_key = 'phase_corr' # fuse with alignment\n",
    "\n",
    "msims = df['msim'].tolist()\n",
    "sims = [msi_utils.get_sim_from_msim(\n",
    "    msim,\n",
    "    # scale='scale0', # set the scale to be used for fusion\n",
    "    scale='scale5', # set the scale to be used for fusion\n",
    "    )\n",
    "    for msim in msims]\n",
    "\n",
    "fused = fusion.fuse_to_multiscale_ome_zarr(\n",
    "    fuse_kwargs={\n",
    "        \"sims\": sims,\n",
    "        \"transform_key\": fusion_transform_key,\n",
    "        \"output_chunksize\": {dim: 256 for dim in ['z', 'y', 'x']},\n",
    "        # \"output_shape\": {'z': 500, 'y': 500, 'x': 500}, # option to test smaller output\n",
    "        \"blending_widths\": {\"z\": 1000, \"y\": 1000, \"x\": 1000},\n",
    "    },\n",
    "    output_zarr_url=output_zarr_url,\n",
    "    overwrite=True, # whether to overwrite existing output Zarr (if it exists)\n",
    "    # optionally, we can use ray for parallelization (`pip install \"ray[default]\"`)\n",
    "    # batch_func=misc_utils.process_batch_using_ray,\n",
    "    # n_batch=4, # number of chunk fusions to schedule / submit at a time\n",
    "    # batch_func_kwargs={\n",
    "    #     'num_cpus': 4 # number of processes for parallel processing to use with ray\n",
    "    #     },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544a466c",
   "metadata": {},
   "source": [
    "## Visualize the fused dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda9ecab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interrupt the notebook cell to stop the viewer\n",
    "vis_utils.view_neuroglancer(\n",
    "    sims=[fused],\n",
    "    ome_zarr_paths=[output_zarr_url],\n",
    "    channel_coord=0,\n",
    "    transform_key=fusion_transform_key,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
